{"componentChunkName":"component---src-templates-blog-post-js","path":"/time-complexity/","result":{"data":{"site":{"siteMetadata":{"title":"Interviewing Blog"}},"markdownRemark":{"id":"205f2b50-9573-5bb0-8951-9c9641a448ec","excerpt":"People who writes code everyday in their jobs have many things to consider while building software. They need to keep their code maintainable and well…","html":"<p>People who writes code everyday in their jobs have many things to consider while building software. They need to keep their code maintainable and well documented. They must also sometimes worry about scale and performance. How does an engineer know if their solution is a good one? Among the things that they could measure are running time and memory usage. This leads them to two important questions:</p>\n<ol>\n<li>How long does my program take to run?</li>\n<li>How much memory does my program take to run?</li>\n</ol>\n<p>To answer these questions we might try to time our functions or inspect how much memory our software uses. Here is one such attempt:</p>\n<div class=\"gatsby-highlight\" data-language=\"js\"><pre class=\"language-js\"><code class=\"language-js\"><span class=\"token keyword\">function</span> <span class=\"token function\">fastCode</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n  <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span>i <span class=\"token operator\">=</span> <span class=\"token number\">0</span><span class=\"token punctuation\">;</span> i <span class=\"token operator\">&lt;</span> <span class=\"token number\">50000</span><span class=\"token punctuation\">;</span> <span class=\"token operator\">++</span>i<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token comment\">// do something</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span>\n\nconsole<span class=\"token punctuation\">.</span><span class=\"token function\">time</span><span class=\"token punctuation\">(</span><span class=\"token string\">'fastCode'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token function\">fastCode</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\nconsole<span class=\"token punctuation\">.</span><span class=\"token function\">timeEnd</span><span class=\"token punctuation\">(</span><span class=\"token string\">'fastCode'</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\">// fastCode: 23ms - timer ended</span></code></pre></div>\n<p>Performance depends on the machine. Adding exact running time does not show how our code would perform on a grand scale. It can have different exact times on different hardware. The way we define the running time of our algorithm should be independent of the hardware it is running on. Even for the same algorithm there can be different times based on how our data is organized.</p>\n<p>Complexity depends on the size of the problem. It take different time or space depending on the size of the input.</p>\n<p>Instead of asking how much time does it take we can ask how does this function grows. Asymptotic analysis is the study of algorithm’s growth rate.</p>\n<p>could show how different sized inputs have different running time</p>\n<p>give khan academy example of class room growth is linear and online shool growth is exponential </p>\n<p>could insert code from binary search and show how it works for small and large numbers of inputs.</p>\n<h2>Asymptotic bounding</h2>\n<p>Asymptote: nature of a function as it reaches a very large value and is “bounded”</p>\n<p><img src=\"./asymptote.png\" alt=\"asymptote\"></p>\n<p>We can really see how our code is performing at the tail end of the asymptotic function.</p>\n<p>We are mostly interested in the algorithm’s worst possible running time. Since the best case could be as simple as running a single set of instructions.</p>\n<p>Asymptotic notation: </p>\n<h2>Big Oh O(n)</h2>\n<p>The Big-O notation shows us the asymptotic upper bound of our code as in the time of space needed for the worst case. In other word it is a ceiling on the growth of the code we are analyzing.</p>\n<p><img src=\"./big-oh.png\" alt=\"big oh\"></p>\n<p>O(g(n)) = { f(n): there exist positive constants c and n<sub>0</sub>\nsuch that 0 ≤ f(n) ≤ cg(n) for all n ≥ n<sub>0</sub> }</p>\n<p>We need to tighten our bound</p>\n<h2>Big omega</h2>\n<p>best case</p>\n<p>floor growth rate</p>\n<p>asymptotic lower bound</p>\n<p>The least work we can do or the fastest our code can run.</p>\n<h2>Big theta</h2>\n<p>Exact bound</p>\n<p>asymptotically tight bound</p>\n<h2>How</h2>\n<p>Total running time of a function in found by adding the running time of all of the statements in the function. Simple operations take constant time O(1). For conditional statement, the branch that takes the most time is considered. For loops, we multiply the time complexity of the statements within the loop by the number of times the loop is run. So, a loop that runs some constant time operations <code class=\"language-text\">n</code> times is said to have O(n) complexity. Following that train of thought: a loop with <code class=\"language-text\">n</code> iterations which has another loop with <code class=\"language-text\">m</code> iterations has a complexity of O(n*m) given that the loops contain constant time operations.</p>\n<p>We can show a line graph</p>\n<p>T(n) = an + b</p>\n<p>-> big oh is O(n) dropping a and b</p>\n<p>for quadratic time</p>\n<p>T(n) = cn<sup>2</sup> + dn + e</p>\n<p>here the graph of n<sup>2</sup> grows much faster than dn</p>\n<p>so complexity is O(n<sup>2</sup>)</p>\n<p>show line by line complexity</p>\n<h2>Commonly found complexities</h2>\n<table>\n<thead>\n<tr>\n<th>Notation</th>\n<th>Name</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>O(1)</td>\n<td>Constant</td>\n</tr>\n<tr>\n<td>O(log(n))</td>\n<td>Logarithmic</td>\n</tr>\n<tr>\n<td>O(n)</td>\n<td>Linear</td>\n</tr>\n<tr>\n<td>O(nlog(n))</td>\n<td>Log-linear</td>\n</tr>\n<tr>\n<td>O(n<sup>2</sup>)</td>\n<td>Quadratic</td>\n</tr>\n<tr>\n<td>O(n<sup>c</sup>)</td>\n<td>Polynomial</td>\n</tr>\n<tr>\n<td>O(c<sup>n</sup>)</td>\n<td>Exponential</td>\n</tr>\n</tbody>\n</table>\n<p><img src=\"common-big-o.png\" alt=\"common cases\"></p>","frontmatter":{"title":"Time Complexity","date":"May 10, 2020","description":"Time complexity of your code"}}},"pageContext":{"slug":"/time-complexity/","previous":{"fields":{"slug":"/hello-world/"},"frontmatter":{"title":"Hello World"}},"next":null}}}